{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coursera Retrieving processing visualizing Data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVXecgQJc9CC",
        "colab_type": "text"
      },
      "source": [
        "#Spider.py\n",
        "The first program (spider.py) program crawls a web site and pulls a series of pages into the database (spider.sqlite), recording the links between pages. You can restart the process at any time by removing the spider.sqlite file and rerunning spider.py."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlHHt-Zeb5Cu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d512d574-ecb6-42a6-ade4-3b51db4a32ac"
      },
      "source": [
        "import sqlite3\n",
        "import urllib.error\n",
        "import ssl\n",
        "from urllib.parse import urljoin\n",
        "from urllib.parse import urlparse\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Ignore SSL certificate errors\n",
        "ctx = ssl.create_default_context()\n",
        "ctx.check_hostname = False\n",
        "ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "conn = sqlite3.connect('/content/drive/My Drive/Coursera Learning (OWN)/Python Retrieving Processing Visualizing Data/spider.sqlite')\n",
        "cur = conn.cursor()\n",
        "\n",
        "cur.execute('''CREATE TABLE IF NOT EXISTS Pages\n",
        "    (id INTEGER PRIMARY KEY, url TEXT UNIQUE, html TEXT,\n",
        "     error INTEGER, old_rank REAL, new_rank REAL)''')\n",
        "\n",
        "cur.execute('''CREATE TABLE IF NOT EXISTS Links\n",
        "    (from_id INTEGER, to_id INTEGER)''')\n",
        "\n",
        "cur.execute('''CREATE TABLE IF NOT EXISTS Webs (url TEXT UNIQUE)''')\n",
        "\n",
        "# Check to see if we are already in progress...\n",
        "cur.execute('SELECT id,url FROM Pages WHERE html is NULL and error is NULL ORDER BY RANDOM() LIMIT 1')\n",
        "row = cur.fetchone()\n",
        "if row is not None:\n",
        "    print(\"Restarting existing crawl.  Remove spider.sqlite to start a fresh crawl.\")\n",
        "else :\n",
        "    starturl = input('Enter web url or enter: ')\n",
        "    if ( len(starturl) < 1 ) : starturl = 'http://seu.edu.bd/'\n",
        "    if ( starturl.endswith('/') ) : starturl = starturl[:-1]\n",
        "    web = starturl\n",
        "    if ( starturl.endswith('.htm') or starturl.endswith('.html') ) :\n",
        "        pos = starturl.rfind('/')\n",
        "        web = starturl[:pos]\n",
        "\n",
        "    if ( len(web) > 1 ) :\n",
        "        cur.execute('INSERT OR IGNORE INTO Webs (url) VALUES ( ? )', ( web, ) )\n",
        "        cur.execute('INSERT OR IGNORE INTO Pages (url, html, new_rank) VALUES ( ?, NULL, 1.0 )', ( starturl, ) )\n",
        "        conn.commit()\n",
        "\n",
        "# Get the current webs\n",
        "cur.execute('''SELECT url FROM Webs''')\n",
        "webs = list()\n",
        "for row in cur:\n",
        "    webs.append(str(row[0]))\n",
        "\n",
        "print(webs)\n",
        "\n",
        "many = 0\n",
        "while True:\n",
        "    if ( many < 1 ) :\n",
        "        sval = input('How many pages:')\n",
        "        if ( len(sval) < 1 ) : break\n",
        "        many = int(sval)\n",
        "    many = many - 1\n",
        "\n",
        "    cur.execute('SELECT id,url FROM Pages WHERE html is NULL and error is NULL ORDER BY RANDOM() LIMIT 1')\n",
        "    try:\n",
        "        row = cur.fetchone()\n",
        "        # print row\n",
        "        fromid = row[0]\n",
        "        url = row[1]\n",
        "    except:\n",
        "        print('No unretrieved HTML pages found')\n",
        "        many = 0\n",
        "        break\n",
        "\n",
        "    print(fromid, url, end=' ')\n",
        "\n",
        "    # If we are retrieving this page, there should be no links from it\n",
        "    cur.execute('DELETE from Links WHERE from_id=?', (fromid, ) )\n",
        "    try:\n",
        "        document = urlopen(url, context=ctx)\n",
        "\n",
        "        html = document.read()\n",
        "        if document.getcode() != 200 :\n",
        "            print(\"Error on page: \",document.getcode())\n",
        "            cur.execute('UPDATE Pages SET error=? WHERE url=?', (document.getcode(), url) )\n",
        "\n",
        "        if 'text/html' != document.info().get_content_type() :\n",
        "            print(\"Ignore non text/html page\")\n",
        "            cur.execute('DELETE FROM Pages WHERE url=?', ( url, ) )\n",
        "            conn.commit()\n",
        "            continue\n",
        "\n",
        "        print('('+str(len(html))+')', end=' ')\n",
        "\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "    except KeyboardInterrupt:\n",
        "        print('')\n",
        "        print('Program interrupted by user...')\n",
        "        break\n",
        "    except:\n",
        "        print(\"Unable to retrieve or parse page\")\n",
        "        cur.execute('UPDATE Pages SET error=-1 WHERE url=?', (url, ) )\n",
        "        conn.commit()\n",
        "        continue\n",
        "\n",
        "    cur.execute('INSERT OR IGNORE INTO Pages (url, html, new_rank) VALUES ( ?, NULL, 1.0 )', ( url, ) )\n",
        "    cur.execute('UPDATE Pages SET html=? WHERE url=?', (memoryview(html), url ) )\n",
        "    conn.commit()\n",
        "\n",
        "    # Retrieve all of the anchor tags\n",
        "    tags = soup('a')\n",
        "    count = 0\n",
        "    for tag in tags:\n",
        "        href = tag.get('href', None)\n",
        "        if ( href is None ) : continue\n",
        "        # Resolve relative references like href=\"/contact\"\n",
        "        up = urlparse(href)\n",
        "        if ( len(up.scheme) < 1 ) :\n",
        "            href = urljoin(url, href)\n",
        "        ipos = href.find('#')\n",
        "        if ( ipos > 1 ) : href = href[:ipos]\n",
        "        if ( href.endswith('.png') or href.endswith('.jpg') or href.endswith('.gif') ) : continue\n",
        "        if ( href.endswith('/') ) : href = href[:-1]\n",
        "        # print href\n",
        "        if ( len(href) < 1 ) : continue\n",
        "\n",
        "\t\t# Check if the URL is in any of the webs\n",
        "        found = False\n",
        "        for web in webs:\n",
        "            if ( href.startswith(web) ) :\n",
        "                found = True\n",
        "                break\n",
        "        if not found : continue\n",
        "\n",
        "        cur.execute('INSERT OR IGNORE INTO Pages (url, html, new_rank) VALUES ( ?, NULL, 1.0 )', ( href, ) )\n",
        "        count = count + 1\n",
        "        conn.commit()\n",
        "\n",
        "        cur.execute('SELECT id FROM Pages WHERE url=? LIMIT 1', ( href, ))\n",
        "        try:\n",
        "            row = cur.fetchone()\n",
        "            toid = row[0]\n",
        "        except:\n",
        "            print('Could not retrieve id')\n",
        "            continue\n",
        "        # print fromid, toid\n",
        "        cur.execute('INSERT OR IGNORE INTO Links (from_id, to_id) VALUES ( ?, ? )', ( fromid, toid ) )\n",
        "\n",
        "\n",
        "    print(count)\n",
        "\n",
        "conn.close()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter web url or enter: http://seu.edu.bd/\n",
            "['http://seu.edu.bd']\n",
            "How many pages:100\n",
            "1 http://seu.edu.bd (77103) 109\n",
            "66 http://seu.edu.bd/downloads/7th_Convocation_Students_List.pdf Ignore non text/html page\n",
            "20 http://seu.edu.bd/admission.php?id=scholarship_waiver (17951) 67\n",
            "40 http://seu.edu.bd/research.php?id=journals (16711) 66\n",
            "56 http://seu.edu.bd/center_band.php?id=acacal (20099) 68\n",
            "50 http://seu.edu.bd/campus_life.php?id=health_safety (16374) 69\n",
            "22 http://seu.edu.bd/admission.php?id=admission_form (17658) 70\n",
            "34 http://seu.edu.bd/administration.php?id=dcs (22889) 73\n",
            "21 http://seu.edu.bd/admission.php?id=foreign_students (18594) 67\n",
            "19 http://seu.edu.bd/admission.php?id=tuition_fee (17606) 67\n",
            "25 http://seu.edu.bd/administration.php?id=the_pro_vice_chancellor_office (18486) 73\n",
            "58 http://seu.edu.bd/clubs.php?id=debate_club (19736) 69\n",
            "12 http://seu.edu.bd/dept/bba.php?id=overview (10189) 29\n",
            "71 http://seu.edu.bd/admission/downloads/Entry_form.pdf Ignore non text/html page\n",
            "95 http://seu.edu.bd/dept/bba.php?id=undergraduate/evaluation (12012) 29\n",
            "75 http://seu.edu.bd/clubs.php?id=art_club (19736) 69\n",
            "41 http://seu.edu.bd/seujse/index.php (5546) 12\n",
            "113 http://seu.edu.bd/seujse/contact_us.php (5418) 12\n",
            "31 http://seu.edu.bd/administration.php?id=it_administration_office (21796) 73\n",
            "45 http://seu.edu.bd/campus_life.php?id=student_affairs (74475) 69\n",
            "77 http://seu.edu.bd/clubs.php?id=welfare_club (19736) 69\n",
            "91 http://seu.edu.bd/dept/bba.php?id=undergraduate/courses (9451) 30\n",
            "73 http://seu.edu.bd/clubs.php?id=sports_club (19736) 69\n",
            "51 http://seu.edu.bd/campus_life.php?id=campus (16820) 69\n",
            "10 http://seu.edu.bd/about.php?id=goal_and_scope (16804) 67\n",
            "9 http://seu.edu.bd/about.php?id=vision (15975) 67\n",
            "60 http://seu.edu.bd/center_band.php?id=health_counseling (16367) 68\n",
            "52 http://seu.edu.bd/campus_life.php?id=accommodation (94763) 69\n",
            "16 http://seu.edu.bd/admission.php?id=admission_notice (17866) 68\n",
            "115 http://seu.edu.bd/admission/downloads/AdmissioninformationSummer2020.pdf Ignore non text/html page\n",
            "72 http://seu.edu.bd/admission/downloads/ID_CARD_FORM.pdf Ignore non text/html page\n",
            "104 http://seu.edu.bd/dept/bba.php?id=director_message (10993) 29\n",
            "68 http://seu.edu.bd/footer_content.php?id=disclaimer (16260) 62\n",
            "32 http://seu.edu.bd/administration.php?id=isdt (24035) 73\n",
            "55 http://seu.edu.bd/center_band.php?id=graduate_education (18246) 73\n",
            "96 http://seu.edu.bd/dept/bba.php?id=research/faculty (30079) 51\n",
            "80 http://seu.edu.bd/clubs.php?id=law_club (19736) 69\n",
            "29 http://seu.edu.bd/administration.php?id=library_office (23973) 73\n",
            "64 http://seu.edu.bd/featured_faculty.php?id=mafizul_islam (17167) 64\n",
            "120 http://seu.edu.bd/featured_faculty.php?id=shahriar_manzoor (17065) 64\n",
            "13 http://seu.edu.bd/arts_school.php (19325) 72\n",
            "27 http://seu.edu.bd/administration.php?id=accounts_and_finance_controller_office (22377) 73\n",
            "117 http://seu.edu.bd/dept/mds.php?id=overview (9134) 21\n",
            "11 http://seu.edu.bd/science_school.php (19366) 72\n",
            "84 http://seu.edu.bd/dept/bba.php?id=vision (9353) 29\n",
            "114 http://seu.edu.bd/dept/bba/downloads/courses/BBA Program Structure.docx Unable to retrieve or parse page\n",
            "79 http://seu.edu.bd/clubs.php?id=business_club (19736) 69\n",
            "112 http://seu.edu.bd/seujse/vol_8_no_12_jun_dec_2014.php (10386) 12\n",
            "131 http://seu.edu.bd/dept/mds.php?id=graduate/mds (8433) 21\n",
            "119 http://seu.edu.bd/featured_faculty.php?id=meer_mobashsher (17769) 64\n",
            "105 http://seu.edu.bd/seujse/scopes.php (6799) 12\n",
            "8 http://seu.edu.bd/about.php?id=mission (16449) 67\n",
            "87 http://seu.edu.bd/dept/bba.php?id=admission (11354) 29\n",
            "46 http://seu.edu.bd/campus_life.php?id=international_affairs (85173) 69\n",
            "67 http://seu.edu.bd/notice_board.php (682685) 256\n",
            "90 http://seu.edu.bd/dept/bba.php?id=undergraduate/bba (10777) 29\n",
            "106 http://seu.edu.bd/seujse/editorial_board.php (29276) 12\n",
            "133 http://seu.edu.bd/dept/mds.php?id=scholarship (7980) 21\n",
            "86 http://seu.edu.bd/dept/bba.php?id=facilities (14558) 29\n",
            "115 http://seu.edu.bd/dept/english.php?id=overview (8530) 26\n",
            "37 http://seu.edu.bd/research.php?id=irt (17602) 65\n",
            "157 http://seu.edu.bd/dept/english.php?id=staff (9792) 26\n",
            "74 http://seu.edu.bd/clubs.php?id=cultural_club (19736) 69\n",
            "142 http://seu.edu.bd/dept/architecture.php?id=overview (8561) 22\n",
            "4 http://seu.edu.bd/contact.php (18962) 61\n",
            "150 http://seu.edu.bd/downloads/2nd Admission Test Result.pdf Unable to retrieve or parse page\n",
            "149 http://seu.edu.bd/downloads/3rd Admission test result Spring 2017.pdf Unable to retrieve or parse page\n",
            "138 http://seu.edu.bd/dept/mds.php?id=contact (7597) 21\n",
            "65 http://seu.edu.bd/news_and_events.php (1784448) 1479\n",
            "175 http://seu.edu.bd/dept/architecture.php?id=faculty (20916) 24\n",
            "109 http://seu.edu.bd/seujse/vol_10_no_2_dec_2016.php (11414) 12\n",
            "35 http://seu.edu.bd/administration.php?id=irt_office (18395) 73\n",
            "15 http://seu.edu.bd/iqac.php (26252) 60\n",
            "92 http://seu.edu.bd/dept/bba.php?id=graduate/overview (10429) 29\n",
            "111 http://seu.edu.bd/seujse/vol_9_no_12_dec_2015.php (13367) 12\n",
            "39 http://seu.edu.bd/research.php?id=centres (18636) 65\n",
            "127 http://seu.edu.bd/dept/mds.php?id=vision (7150) 21\n",
            "47 http://seu.edu.bd/campus_life.php?id=alumni_affairs (72505) 69\n",
            "141 http://seu.edu.bd/dept/textile.php?id=overview (8350) 20\n",
            "44 http://seu.edu.bd/campus_life.php?id=career_services (104043) 69\n",
            "129 http://seu.edu.bd/dept/mds.php?id=facilities (9794) 21\n",
            "208 http://seu.edu.bd/dept/textile.php?id=news_events (11314) 20\n",
            "3 http://seu.edu.bd/career/index.php (28547) 57\n",
            "116 http://seu.edu.bd/dept/law.php?id=overview (9766) 31\n",
            "136 http://seu.edu.bd/dept/mds.php?id=class_routine (7106) 21\n",
            "186 http://seu.edu.bd/dept/architecture.php?id=undergraduate/bsc_courses (12603) 22\n",
            "110 http://seu.edu.bd/seujse/vol_10_no_1_jun_2016.php (12798) 12\n",
            "93 http://seu.edu.bd/dept/bba.php?id=graduate/mba_regular (9633) 30\n",
            "155 http://seu.edu.bd/downloads/UGC Notice.pdf Unable to retrieve or parse page\n",
            "211 http://seu.edu.bd/career/facApp19.docx Ignore non text/html page\n",
            "88 http://seu.edu.bd/dept/bba.php?id=undergraduate/scholarship (15681) 29\n",
            "26 http://seu.edu.bd/administration.php?id=registrar_office (29520) 73\n",
            "23 http://seu.edu.bd/administration.php?id=seut_office (22123) 73\n",
            "237 http://seu.edu.bd/dept/law.php?id=contact (9118) 31\n",
            "235 http://seu.edu.bd/dept/law.php?id=exam_schedule (9950) 33\n",
            "48 http://seu.edu.bd/clubs1.php Unable to retrieve or parse page\n",
            "209 http://seu.edu.bd/dept/textile.php?id=contact (7415) 20\n",
            "101 http://seu.edu.bd/dept/bba.php?id=news_events (15605) 29\n",
            "6 http://seu.edu.bd/about.php?id=seu_trust_ogranogram (16109) 67\n",
            "156 http://seu.edu.bd/dept/english.php?id=faculty (24188) 26\n",
            "How many pages:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BO-liVLwDSU",
        "colab_type": "text"
      },
      "source": [
        "#sprank.py\n",
        "Once you have a few pages in the database, you can run page rank on the pages using the sprank.py program. You simply tell it how many page rank iterations to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVXMwFNcrvFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "outputId": "f7965a07-b328-4aae-e555-006cec56937e"
      },
      "source": [
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('/content/drive/My Drive/Coursera Learning (OWN)/Python Retrieving Processing Visualizing Data/spider.sqlite')\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Find the ids that send out page rank - we only are interested\n",
        "# in pages in the SCC that have in and out links\n",
        "cur.execute('''SELECT DISTINCT from_id FROM Links''')\n",
        "from_ids = list()\n",
        "for row in cur: \n",
        "    from_ids.append(row[0])\n",
        "\n",
        "# Find the ids that receive page rank \n",
        "to_ids = list()\n",
        "links = list()\n",
        "cur.execute('''SELECT DISTINCT from_id, to_id FROM Links''')\n",
        "for row in cur:\n",
        "    from_id = row[0]\n",
        "    to_id = row[1]\n",
        "    if from_id == to_id : continue\n",
        "    if from_id not in from_ids : continue\n",
        "    if to_id not in from_ids : continue\n",
        "    links.append(row)\n",
        "    if to_id not in to_ids : to_ids.append(to_id)\n",
        "\n",
        "# Get latest page ranks for strongly connected component\n",
        "prev_ranks = dict()\n",
        "for node in from_ids:\n",
        "    cur.execute('''SELECT new_rank FROM Pages WHERE id = ?''', (node, ))\n",
        "    row = cur.fetchone()\n",
        "    prev_ranks[node] = row[0]\n",
        "\n",
        "sval = input('How many iterations:')\n",
        "many = 1\n",
        "if ( len(sval) > 0 ) : many = int(sval)\n",
        "\n",
        "# Sanity check\n",
        "if len(prev_ranks) < 1 : \n",
        "    print(\"Nothing to page rank.  Check data.\")\n",
        "    quit()\n",
        "\n",
        "# Lets do Page Rank in memory so it is really fast\n",
        "for i in range(many):\n",
        "    # print prev_ranks.items()[:5]\n",
        "    next_ranks = dict();\n",
        "    total = 0.0\n",
        "    for (node, old_rank) in list(prev_ranks.items()):\n",
        "        total = total + old_rank\n",
        "        next_ranks[node] = 0.0\n",
        "    # print total\n",
        "\n",
        "    # Find the number of outbound links and sent the page rank down each\n",
        "    for (node, old_rank) in list(prev_ranks.items()):\n",
        "        # print node, old_rank\n",
        "        give_ids = list()\n",
        "        for (from_id, to_id) in links:\n",
        "            if from_id != node : continue\n",
        "           #  print '   ',from_id,to_id\n",
        "\n",
        "            if to_id not in to_ids: continue\n",
        "            give_ids.append(to_id)\n",
        "        if ( len(give_ids) < 1 ) : continue\n",
        "        amount = old_rank / len(give_ids)\n",
        "        # print node, old_rank,amount, give_ids\n",
        "    \n",
        "        for id in give_ids:\n",
        "            next_ranks[id] = next_ranks[id] + amount\n",
        "    \n",
        "    newtot = 0\n",
        "    for (node, next_rank) in list(next_ranks.items()):\n",
        "        newtot = newtot + next_rank\n",
        "    evap = (total - newtot) / len(next_ranks)\n",
        "\n",
        "    # print newtot, evap\n",
        "    for node in next_ranks:\n",
        "        next_ranks[node] = next_ranks[node] + evap\n",
        "\n",
        "    newtot = 0\n",
        "    for (node, next_rank) in list(next_ranks.items()):\n",
        "        newtot = newtot + next_rank\n",
        "\n",
        "    # Compute the per-page average change from old rank to new rank\n",
        "    # As indication of convergence of the algorithm\n",
        "    totdiff = 0\n",
        "    for (node, old_rank) in list(prev_ranks.items()):\n",
        "        new_rank = next_ranks[node]\n",
        "        diff = abs(old_rank-new_rank)\n",
        "        totdiff = totdiff + diff\n",
        "\n",
        "    avediff = totdiff / len(prev_ranks)\n",
        "    print(i+1, avediff)\n",
        "\n",
        "    # rotate\n",
        "    prev_ranks = next_ranks\n",
        "\n",
        "# Put the final ranks back into the database\n",
        "print(list(next_ranks.items())[:5])\n",
        "cur.execute('''UPDATE Pages SET old_rank=new_rank''')\n",
        "for (id, new_rank) in list(next_ranks.items()) :\n",
        "    cur.execute('''UPDATE Pages SET new_rank=? WHERE id=?''', (new_rank, id))\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How many iterations:50\n",
            "1 0.3637272827030791\n",
            "2 0.06646279829773083\n",
            "3 0.06235835718227072\n",
            "4 0.05869393911749885\n",
            "5 0.055089194160974624\n",
            "6 0.0516862895125577\n",
            "7 0.04849091573070124\n",
            "8 0.04549271456422716\n",
            "9 0.04267983997978439\n",
            "10 0.04004088168328439\n",
            "11 0.03756509306478826\n",
            "12 0.03524238607232345\n",
            "13 0.0330632955741384\n",
            "14 0.03101894156295168\n",
            "15 0.029100993078991305\n",
            "16 0.02730163427604185\n",
            "17 0.025613532573243822\n",
            "18 0.024029808774352682\n",
            "19 0.022544009034315474\n",
            "20 0.021150078559165977\n",
            "21 0.019842336932087125\n",
            "22 0.018615454965098904\n",
            "23 0.017464432982046925\n",
            "24 0.016384580444380622\n",
            "25 0.015371496836705136\n",
            "26 0.014421053734205862\n",
            "27 0.013529377978874288\n",
            "28 0.012692835895970617\n",
            "29 0.011908018486408167\n",
            "30 0.01117172753471542\n",
            "31 0.010480962575962925\n",
            "32 0.009832908668545895\n",
            "33 0.009224924922993948\n",
            "34 0.008654533740061249\n",
            "35 0.008119410714244612\n",
            "36 0.00761737516157932\n",
            "37 0.007146381233116597\n",
            "38 0.006704509577870385\n",
            "39 0.006289959521254285\n",
            "40 0.005901041727139604\n",
            "41 0.0055361713136270405\n",
            "42 0.005193861394483147\n",
            "43 0.004872717019919685\n",
            "44 0.004571429492022406\n",
            "45 0.004288771031664965\n",
            "46 0.004023589775177922\n",
            "47 0.0037748050803800863\n",
            "48 0.003541403122845589\n",
            "49 0.003322432764458303\n",
            "50 0.003117001677425038\n",
            "[(1, -3.1579677144893343e-16), (20, 0.060870615157515545), (40, 0.060870615157515545), (56, -3.174330593825601e-16), (50, 0.060870615157515545)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVEMD2glwSdA",
        "colab_type": "text"
      },
      "source": [
        "#spdump.py\n",
        "If you want to dump the contents of the spider.sqlite file, you can run spdump.py as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlVb7o1XsNxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "outputId": "998f46ce-7a99-4995-b7d0-2faeb83312e5"
      },
      "source": [
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('/content/drive/My Drive/Coursera Learning (OWN)/Python Retrieving Processing Visualizing Data/spider.sqlite')\n",
        "cur = conn.cursor()\n",
        "\n",
        "cur.execute('''SELECT COUNT(from_id) AS inbound, old_rank, new_rank, id, url \n",
        "     FROM Pages JOIN Links ON Pages.id = Links.to_id\n",
        "     WHERE html IS NOT NULL\n",
        "     GROUP BY id ORDER BY inbound DESC''')\n",
        "\n",
        "count = 0\n",
        "for row in cur :\n",
        "    if count < 50 : print(row)\n",
        "    count = count + 1\n",
        "print(count, 'rows.')\n",
        "conn.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1424, 1.0, -3.1579677144893343e-16, 65, 'http://seu.edu.bd/news_and_events.php')\n",
            "(194, 1.0, -3.1579677144893343e-16, 67, 'http://seu.edu.bd/notice_board.php')\n",
            "(109, 1.0, 0.06063936859855249, 3, 'http://seu.edu.bd/career/index.php')\n",
            "(70, 1.0, 3.8132305929671046, 41, 'http://seu.edu.bd/seujse/index.php')\n",
            "(64, 1.0, 0.060870615157515545, 23, 'http://seu.edu.bd/administration.php?id=seut_office')\n",
            "(64, 1.0, 0.060870615157515545, 25, 'http://seu.edu.bd/administration.php?id=the_pro_vice_chancellor_office')\n",
            "(64, 1.0, 0.060870615157515545, 26, 'http://seu.edu.bd/administration.php?id=registrar_office')\n",
            "(64, 1.0, 0.060870615157515545, 27, 'http://seu.edu.bd/administration.php?id=accounts_and_finance_controller_office')\n",
            "(64, 1.0, 0.060870615157515545, 29, 'http://seu.edu.bd/administration.php?id=library_office')\n",
            "(64, 1.0, 0.060870615157515545, 31, 'http://seu.edu.bd/administration.php?id=it_administration_office')\n",
            "(64, 1.0, 0.060870615157515545, 34, 'http://seu.edu.bd/administration.php?id=dcs')\n",
            "(64, 1.0, 0.060870615157515545, 35, 'http://seu.edu.bd/administration.php?id=irt_office')\n",
            "(63, 1.0, 0.060870615157515545, 51, 'http://seu.edu.bd/campus_life.php?id=campus')\n",
            "(63, 1.0, 0.060870615157515545, 52, 'http://seu.edu.bd/campus_life.php?id=accommodation')\n",
            "(62, 1.0, 0.060870615157515545, 50, 'http://seu.edu.bd/campus_life.php?id=health_safety')\n",
            "(61, 1.0, 0.058847207766588826, 44, 'http://seu.edu.bd/campus_life.php?id=career_services')\n",
            "(61, 1.0, 0.058847207766588826, 45, 'http://seu.edu.bd/campus_life.php?id=student_affairs')\n",
            "(61, 1.0, 0.058847207766588826, 46, 'http://seu.edu.bd/campus_life.php?id=international_affairs')\n",
            "(61, 1.0, 0.058847207766588826, 47, 'http://seu.edu.bd/campus_life.php?id=alumni_affairs')\n",
            "(60, 1.0, 0.06092062830465333, 16, 'http://seu.edu.bd/admission.php?id=admission_notice')\n",
            "(60, 1.0, 0.060870615157515545, 19, 'http://seu.edu.bd/admission.php?id=tuition_fee')\n",
            "(60, 1.0, 0.060870615157515545, 20, 'http://seu.edu.bd/admission.php?id=scholarship_waiver')\n",
            "(60, 1.0, 0.060870615157515545, 21, 'http://seu.edu.bd/admission.php?id=foreign_students')\n",
            "(60, 1.0, 0.060870615157515545, 22, 'http://seu.edu.bd/admission.php?id=admission_form')\n",
            "(59, 1.0, 0.060870615157515545, 6, 'http://seu.edu.bd/about.php?id=seu_trust_ogranogram')\n",
            "(59, 1.0, 0.060870615157515545, 8, 'http://seu.edu.bd/about.php?id=mission')\n",
            "(59, 1.0, 0.060870615157515545, 9, 'http://seu.edu.bd/about.php?id=vision')\n",
            "(59, 1.0, 0.060870615157515545, 10, 'http://seu.edu.bd/about.php?id=goal_and_scope')\n",
            "(59, 1.0, 0.060870615157515545, 39, 'http://seu.edu.bd/research.php?id=centres')\n",
            "(58, 1.0, 0.060870615157515545, 37, 'http://seu.edu.bd/research.php?id=irt')\n",
            "(58, 1.0, 0.060870615157515545, 40, 'http://seu.edu.bd/research.php?id=journals')\n",
            "(56, 1.0, 0.060870615157515545, 4, 'http://seu.edu.bd/contact.php')\n",
            "(56, 1.0, 0.06096801373835613, 11, 'http://seu.edu.bd/science_school.php')\n",
            "(56, 1.0, 0.06272439779976982, 12, 'http://seu.edu.bd/dept/bba.php?id=overview')\n",
            "(56, 1.0, 0.06101297324941761, 13, 'http://seu.edu.bd/arts_school.php')\n",
            "(56, 1.0, 0.060870615157515545, 68, 'http://seu.edu.bd/footer_content.php?id=disclaimer')\n",
            "(55, 1.0, 0.060870615157515545, 15, 'http://seu.edu.bd/iqac.php')\n",
            "(54, 1.0, 0.058847207766588826, 32, 'http://seu.edu.bd/administration.php?id=isdt')\n",
            "(52, 1.0, 2.9218393838440075, 96, 'http://seu.edu.bd/dept/bba.php?id=research/faculty')\n",
            "(32, 1.0, -3.1579677144893343e-16, 1, 'http://seu.edu.bd')\n",
            "(20, 1.0, 1.0893966114402587, 117, 'http://seu.edu.bd/dept/mds.php?id=overview')\n",
            "(17, 1.0, 0.002094298833403609, 58, 'http://seu.edu.bd/clubs.php?id=debate_club')\n",
            "(17, 1.0, 2.9218393838440075, 84, 'http://seu.edu.bd/dept/bba.php?id=vision')\n",
            "(17, 1.0, 2.9218393838440075, 86, 'http://seu.edu.bd/dept/bba.php?id=facilities')\n",
            "(17, 1.0, 2.9218393838440075, 87, 'http://seu.edu.bd/dept/bba.php?id=admission')\n",
            "(17, 1.0, 2.9218393838440075, 88, 'http://seu.edu.bd/dept/bba.php?id=undergraduate/scholarship')\n",
            "(17, 1.0, 2.9218393838440075, 90, 'http://seu.edu.bd/dept/bba.php?id=undergraduate/bba')\n",
            "(17, 1.0, 2.9218393838440075, 91, 'http://seu.edu.bd/dept/bba.php?id=undergraduate/courses')\n",
            "(17, 1.0, 2.9218393838440075, 92, 'http://seu.edu.bd/dept/bba.php?id=graduate/overview')\n",
            "(17, 1.0, 2.9218393838440075, 93, 'http://seu.edu.bd/dept/bba.php?id=graduate/mba_regular')\n",
            "90 rows.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK0kSEuJwomb",
        "colab_type": "text"
      },
      "source": [
        "#spjson.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOf6cy4DwqoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6ec87099-5c7e-4554-dfd8-b93bdf52f31f"
      },
      "source": [
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('/content/drive/My Drive/Coursera Learning (OWN)/Python Retrieving Processing Visualizing Data/spider.sqlite')\n",
        "cur = conn.cursor()\n",
        "\n",
        "print(\"Creating JSON output on spider.js...\")\n",
        "howmany = int(input(\"How many nodes? \"))\n",
        "\n",
        "cur.execute('''SELECT COUNT(from_id) AS inbound, old_rank, new_rank, id, url \n",
        "    FROM Pages JOIN Links ON Pages.id = Links.to_id\n",
        "    WHERE html IS NOT NULL AND ERROR IS NULL\n",
        "    GROUP BY id ORDER BY id,inbound''')\n",
        "\n",
        "fhand = open('/content/drive/My Drive/Coursera Learning (OWN)/Python Retrieving Processing Visualizing Data/spider1.js','w')\n",
        "nodes = list()\n",
        "maxrank = None\n",
        "minrank = None\n",
        "for row in cur :\n",
        "    nodes.append(row)\n",
        "    rank = row[2]\n",
        "    if maxrank is None or maxrank < rank: maxrank = rank\n",
        "    if minrank is None or minrank > rank : minrank = rank\n",
        "    if len(nodes) > howmany : break\n",
        "\n",
        "if maxrank == minrank or maxrank is None or minrank is None:\n",
        "    print(\"Error - please run sprank.py to compute page rank\")\n",
        "    quit()\n",
        "\n",
        "fhand.write('spiderJson = {\"nodes\":[\\n')\n",
        "count = 0\n",
        "map = dict()\n",
        "ranks = dict()\n",
        "for row in nodes :\n",
        "    if count > 0 : fhand.write(',\\n')\n",
        "    # print row\n",
        "    rank = row[2]\n",
        "    rank = 19 * ( (rank - minrank) / (maxrank - minrank) ) \n",
        "    fhand.write('{'+'\"weight\":'+str(row[0])+',\"rank\":'+str(rank)+',')\n",
        "    fhand.write(' \"id\":'+str(row[3])+', \"url\":\"'+row[4]+'\"}')\n",
        "    map[row[3]] = count\n",
        "    ranks[row[3]] = rank\n",
        "    count = count + 1\n",
        "fhand.write('],\\n')\n",
        "\n",
        "cur.execute('''SELECT DISTINCT from_id, to_id FROM Links''')\n",
        "fhand.write('\"links\":[\\n')\n",
        "\n",
        "count = 0\n",
        "for row in cur :\n",
        "    # print row\n",
        "    if row[0] not in map or row[1] not in map : continue\n",
        "    if count > 0 : fhand.write(',\\n')\n",
        "    rank = ranks[row[0]]\n",
        "    srank = 19 * ( (rank - minrank) / (maxrank - minrank) ) \n",
        "    fhand.write('{\"source\":'+str(map[row[0]])+',\"target\":'+str(map[row[1]])+',\"value\":3}')\n",
        "    count = count + 1\n",
        "fhand.write(']};')\n",
        "fhand.close()\n",
        "conn.close()\n",
        "\n",
        "print(\"Open force.html in a browser to view the visualization\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating JSON output on spider.js...\n",
            "How many nodes? 25\n",
            "Open force.html in a browser to view the visualization\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}